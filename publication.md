---
layout: work
title: Publication üìï
slug: /publication
---

This page contains a selected list of <b>journal articles</b> and <b>international conference papers</b> that I have authored or published. üòä
<br/> <br/>



<p>
  <b>‚Ä¢ Book Chapter</b> <br/>
  Fundamentals of 6G Communications and Networking, Springer (2023).
  ‚Äì Chapter 28. Convergence of 6G and Wi-Fi Networks, (H. Lee, S. Park, M. Yoo, <b>C. Park</b>, H. Baek, J. Kim)
  ‚Äì Chapter 22. AI-Native Network Algorithms and Architectures, (H. Lee, S. Park, H. Baek, <b>C. Park</b>, S. Son, J. Park, J. Kim)
  ‚Äì Chapter 20. Network Disaggregation, (S. Park, <b>C. Park</b>, J.P. Kim, M. Choi, J. Kim)
</p><br/><br/><br/>

<p>
  <b>‚Ä¢ SCI Journal</b> <br/>
  1. Joint Quantum Reinforcement Learning and Stabilized Control fro Spatio-Temporal Coordination in Metaverse <br/>
  S. Park, J. Chung, ¬≥<b>C. Park</b>, S. Jung, M. Choi, S. Cho, J. Kim <br/>
  <font color='#da70d6'>IEEE Transactions on Mobile Computing</font> <font color='#dc143c'>(<b>Top</b>, IF:7.9)</font>, in Press. <a href="https://ieeexplore.ieee.org/abstract/document/10543150">[Link]</a><br/><br/>
  
  2. Age-of-Information Aware Caching and Delivery for Infrastructure-Assisted Connected Vehicles <br/>
  S. Park, ¬≤<b>C. Park</b>, S. Jung, M. Choi, J. Kim <br/> 
  <font color='#da70d6'>IEEE Transactions on Vehicular Technology</font> <font color='#dc143c'>(IF:6.8)</font>, 73(7), Jul. 2024. <a href="https://ieeexplore.ieee.org/abstract/document/10491361">[Link]</a><br/>
  <font color='#666666'>[TL; DR] An algorithm utilizing Age-of-Information and infrastructure components is suggested to enhance content delivery and data freshness in connected vehicles.</font><br/><br/>
  
  3. Handover Protocol Learning for LEO Satellite Networks: Access Delay and Collision Minimization <br/>
  J.-H. Lee, ¬≤<b>C. Park</b>, S. Park, and A. F. Molisch <br/>
  <font color='#da70d6'>IEEE Transactions on Wireless Communications</font> <font color='#dc143c'>(<b>Top</b>, IF:10.4)</font>, in Press. <a href="https://ieeexplore.ieee.org/abstract/document/10371217">[Link]</a><br/>
  <font color='#666666'>[TL; DR] A deep reinforcement learning-based handover protocol for LEO satellite networks is developed to reduce access delays and collision rates while improving handover success and efficiency. </font><br/><br/>

  4. Learning-based Cooperative Mobility Control for Autonomous Drone-Delivery <br/>
  S. Park, ¬≤<b>C. Park</b>, and J. Kim <br/>
  <font color='#da70d6'>IEEE Transactions on Vehicular Technology</font> <font color='#dc143c'>(IF:6.8)</font>, 73(4):4870-7885, Apr. 2024. <a href="https://ieeexplore.ieee.org/abstract/document/10310117">[Link]</a><br/>
  <font color='#666666'>[TL; DR] The paper introduces a multi-agent deep reinforcement learning algorithm to optimize package delivery and energy efficiency in autonomous drone systems using a communication network-based approach.</font><br/><br/>

  5. Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation <br/>
  S. Park, J. P. Kim, ¬≥<b>C. Park</b>, S. Jung, and J. Kim <br/>
  <font color='#da70d6'>IEEE Communications Magazine</font> <font color='#dc143c'>(<b>Top</b>, IF:11.2)</font>, 62(6), Jun. 2024. <a href="https://ieeexplore.ieee.org/abstract/document/10232949">[Link]</a><br/>
  <font color='#666666'>[TL; DR] Quantum multi-agent reinforcement learning is proposed to enhance parameter efficiency and convergence speed in autonomous mobility systems, leveraging quantum computing and actor-critic networks to overcome the limitations of traditional algorithms.</font><br/><br/>
  
  6. Quantum Multi-Agent Actor-Critic Networks for Cooperative Mobile Access in Multi-UAV Systems <br/>
  ¬π<b>C. Park</b>, W. J. Yun, J. P. Kim, T. K. Rodrigues, S. Park, S. Jung, J. Kim <br/>
  <font color='#da70d6'>IEEE Internet of Things Journal</font> <font color='#dc143c'>(IF:10.6)</font>, 10(22): 20033-20048, Nov. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10143981">[Link]</a><br/>
  <font color='#666666'>[TL; DR] The paper implements quantum multi-agent reinforcement learning algorithm that improves the efficiency and robustness of multi-UAV mobile access systems by using quantum computing to enhance training and service quality in uncertain environments.</font><br/><br/>

  7. Two-Stage Self-Adaptive Task Outsourcing Decision Making for Edge-Assisted Multi-UAV Networks <br/>
  S. Jung, ¬≤<b>C. Park</b>, M. Levorato, J.-H. Kim, and J. Kim <br/>
  <font color='#da70d6'>IEEE Transactions on Vehicular Technology</font> <font color='#dc143c'>(IF:6.8)</font>, 72(11): 14889 - 14905, Nov. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10144676">[Link]</a><br/>
  <font color='#666666'>[TL; DR] A two-stage algorithm is designed to optimize multi-UAV positioning for surveillance and task outsourcing to edge devices, enhancing efficiency and energy consumption in UAV networks.</font><br/><br/>

  8. Two Tales of Platoon Intelligence for Autonomous Mobility Control: Enabling Deep Learning Recipes <br/>
  S. Park, H. Lee, ¬≥<b>C. Park</b>, S. Jung, M. Choi, and J. Kim <br/>
  <font color='#da70d6'>ETRI Journal (Wiley)</font>, 45(5): 735-745, Oct. 2023. <a href="https://onlinelibrary.wiley.com/doi/full/10.4218/etrij.2023-0132">[Link]</a><br/>
  <font color='#666666'>[TL; DR] The paper investigates multi-agent reinforcement learning and neural Myerson auctions to enhance autonomous vehicle and drone control and resource management, emphasizing communication among agents and fair resource allocation.</font><br/><br/>
    
  9. EQuaTE: Efficient Quantum Train Engine for Run-Time Dynamic Analysis and Visual Feedback in Autonomous Driving <br/>
  S. Park, H. Feng, ¬≥<b>C. Park</b>, Y. K. Lee, S. Jung, J. Kim <br/>
  <font color='#da70d6'>IEEE Internet Computing</font> <font color='#dc143c'>(IF:3.2)</font>, 27(5):24-31, Sep.-Oct. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10229500">[Link]</a><br/>
  <font color='#666666'>[TL; DR] A novel software tool that identifies and visualizes barren plateaus in quantum neural networks to enhance training performance in autonomous driving applications is presented.</font><br/><br/>
    
  10. Multi-Agent Reinforcement Learning for Cooperative Air Transportation Services in City-Wide Autonomous Urban Air Mobility <br/>
  ¬π<b>C. Park</b>, G. S. Kim, S. Park, S. Jung, J. Kim <br/>
  <font color='#da70d6'>IEEE Transactions on Intelligent Vehicles</font> <font color='#dc143c'>(IF:8.2)</font>, 8(8):4016-4030, Aug. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10144378">[Link]</a><br/>
  <font color='#666666'>[TL; DR] The paper introduces the multi-agent deep reinforcement learning algorithm with centralized training and distributed execution to improve coordination and efficiency in city-wide urban air mobility systems, enhancing air transportation services.</font><br/><br/>

  11. Workload-Aware Scheduling using Markov Decision Process for Infrastructure-Assisted Learning-Based Multi-UAV Surveillance Networks <br/>
  S. Park, ¬≤<b>C. Park</b>, S. Jung, J.-H. Kim, J. Kim <br/>
  <font color='#da70d6'>IEEE Access (IEEE Vehicular Technology Society Section)</font> <font color='#dc143c'>(IF:3.9)</font>, 11:16533-16548, Feb. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10045685">[Link]</a><br/>
<font color='#666666'>[TL; DR] A novel scheduling algorithm using Markov decision processes is introduced to optimize power transfer and data distribution between UAVs and towers, enhancing surveillance performance and efficiency.</font><br/><br/>
<br/>
  
  <b>‚Ä¢ Conference</b><br/>

  1. Demo: EQuaTE: Efficient Quantum Train Engine Design and Demonstration for Dynamic Software Analysis <br/>
  S. Park, H. Feng, W. J. Yun, ‚Å¥<b>C. Park</b>, Y. K. Lee, S. Jung and J. Kim <br/>
  <font color='#32cd32'>IEEE International Conference on Distributed Computing Systems (ICDCS)</font> <font color='#dc143c'>(<b>Top</b>)</font>, Jul. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10272530">[Link]</a><br/>
  <font color='#666666'>[TL; DR] A software tool that detects and visualizes barren plateaus in quantum neural networks to enhance training and performance in autonomous driving applications is described, with a demonstration video showing the software in action.</font><br/><br/>
  
  2. Poster: Coordinated Multi-Agent Reinforcement Learning for Unmanned Aerial Vehicle Swarms in Autonomous Mobile Access Applications <br/>
  ¬π<b>C. Park</b>, H. Lee, W. J. Yun, S. Park, S. Jung and . Kim <br/>
  <font color='#32cd32'>IEEE International Conference on Distributed Computing Systems (ICDCS)</font> <font color='#dc143c'>(<b>Top</b>)</font>, Jul. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10272444">[Link]</a><br/>
  <font color='#666666'>[TL; DR] The paper proposes a CTDE-based MADRL algorithm for optimizing UAV swarms as mobile base stations, improving coordination and quality of service in autonomous mobile access applications.</font><br/><br/>
  
  3. Multi-Agent Deep Reinforcement Learning for Efficient Passenger Delivery in Urban Air Mobility <br/>
  ¬π<b>C. Park</b>, S. Park, G. S. Kim, S. Jung, J.-H. Kim, J. Kim <br/>
  <font color='#32cd32'>IEEE International Conference on Communications (ICC)</font> <font color='#dc143c'>(Acceptance rate: 38.5%)</font>, May-Jun. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10279436">[Link]</a><br/>
  <font color='#666666'>[TL; DR] The paper introduces a cooperative MADRL algorithm with centralized training and distributed execution to optimize passenger delivery in urban air mobility systems, increasing serviced passengers by 30% and reducing waiting time by 26%.</font><br/><br/>

  4. Hybrid MAC for Military UAV Networks <br/>
  G. S Kim, H. Lee, ¬≥<b>C. Park</b>, S. Jung, J.-H Kim, J. Kim <br/>
  <font color='#32cd32'>IEEE International Conference on Information Networking (ICOIN)</font>, Jan. 2023. <a href="https://ieeexplore.ieee.org/abstract/document/10048910">[Link]</a>
  <br/>
  <font color='#666666'>[TL; DR] A Hybrid MAC model for military UAV networks, using CSMA and TDMA based on UAV mobility, is suggested to enhance communication performance by 40%.</font><br/><br/>
  <br/>
</p>

<p>
  <b>‚Ä¢ Preprints</b><br/>
  1. Software Simulation and Visualization of Quantum Multi-Drone Reinforcement Learning <br/>
  ¬π<b>C. Park</b>, J. P. Kim, W. J. Yun, S. Park, S. Jung, and J. Kim <br/>
  <font color='#ffa500'>arXiv:2211.15375</font> <a href="https://arxiv.org/abs/2211.15375">[Link]</a><br/>
  <font color='#666666'>[TL; DR] A simulation software framework leveraging quantum multi-agent reinforcement learning to control autonomous multi-drones is detailed, achieving improved reward convergence and service quality with fewer trainable parameters.</font><br/><br/>
  
  2. Cooperative Multi-Agent Deep Reinforcement Learning for Reliable and Energy-Efficient Mobile Access via Multi-UAV Control <br/>
  ¬π<b>C. Park</b>, S. Park, S. Jung, C. Cordeiro, and J. Kim <br/>
  <font color='#ffa500'>arXiv:2210.00945</font> <a href="https://arxiv.org/abs/2210.00945">[Link]</a><br/>
  <font color='#666666'>[TL; DR] A multi-agent deep reinforcement learning algorithm is devised to optimize UAV positioning as mobile base stations, improving energy efficiency and reliability in mobile access networks for intelligent transportation systems.</font><br/><br/>
</p>
